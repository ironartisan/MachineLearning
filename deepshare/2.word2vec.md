# Word2vec

> 选自论文[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)

## 目标
- 什么是n-gram？
- 什么是词向量？有什么种类，以及生成词向量的方式有哪些？
- 分布式词向量的优点
- word2vec工具中的两种模型与传统神经网络模型的区别，为什么要这样做，优点在哪，除此之外还有什么改进的方法
- 分析神经网络语言模型、CBOW和Skip-gram模型的数据流程图。
- 根据实验结果分析为什么论文中表4中skip-gram比CBOW的模型效果好。
- 搞懂代码的各部分组成及功能





