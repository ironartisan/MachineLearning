
# 优化算法

## 梯度下降法(Gradient Descent)

梯度下降法目前主要分为三种方法,区别在于每次参数更新时计算的样本数据量不同：批量梯度下降法(BGD, Batch Gradient Descent)，随机梯度下降法(SGD, Stochastic Gradient Descent)及小批量梯度下降法(Mini-batch Gradient Descent)。


## 参考链接
* <https://zhuanlan.zhihu.com/p/55150256>
* <https://www.cnblogs.com/guoyaohua/p/8542554.html>