# 008

**英文名称：** Convolutional Neural Networks for Sentence Classification

**中文名称：** 基于卷积神经网络的句子分类

**论文地址：** http://arxiv.org/abs/1408.5882

**期刊/时间：** EMNLP 2014

## 前置知识

## 摘要

- **问题是什么？**
- **我们要做什么？**
- **大概怎么做的**
- **实验效果**

  - 我们报告了一系列关于卷积神经网络（CNN）的实验，该网络是在预先训练好的单词向量之上训练的，用于句子级分类任务。
  - 我们表明，一个简单的CNN，几乎没有超参数调整和静态向量，在多个基准上取得了优异的成绩。通过微调学习特定任务的向量，可以进一步提高性能。
  - 我们还提出了对结构的简单修改，以允许使用特定任务和静态向量。
  - 本文讨论的CNN模型在7项任务中的4项上提高了技术水平，其中包括情感分析和问题分类。

## 介绍

按照起承转合的思想阅读。
- **起。做的哪方面工作？**
  - 近年来，深度学习模型在计算机视觉（Krizhevsky等人，2012）和语音识别（Graves等人，2013）方面取得了显著的成果。在自然语言处理中，深度学习方法的大部分工作涉及通过神经语言模型学习单词向量表征（Bengio等人，2003；Yih等人，2011；Mikolov等人，2013），并对学习到的单词向量进行组合分类（Collobert等人，2011）。
- **承。相关工作**
  - 词向量，其中词从稀疏的、1-of-V的编码（这里V是词汇量大小）通过隐藏层投射到一个较低维度的向量空间，本质上是特征提取器，在其维度上编码词的语义特征。在这样的密集表征中，语义上接近的词在低维向量空间中也同样是接近的，即欧氏或余弦距离。
- **转。相关工作的不足和转机**
  - CNN将带有卷积滤波的层应用于局部特征中。CNN模型最初是为计算机视觉而发明的，后来被证明对NLP有效，并在语义解析（Yih等人，2014）、搜索查询检索（Shen等人，2014）、句子建模（Kalchbrenner等人，2014）和其他传统NLP任务（Collobert等人，2011）中取得了优异的成绩。
- **合。本文工作**
  - 在目前的工作中，我们在一个无监督的神经语言模型中获得的单词向量的基础上，训练一个简单的CNN，并有一层卷积。这些向量是由Mikolov等人（2013）在谷歌新闻的1000亿字上训练出来的，并且是公开的。
  - 尽管没有对超参数进行什么调整，这个简单的模型在多个基准上取得了优异的成绩，这表明预训练的向量是 "通用 "的特征提取器，可以用于各种分类任务。通过微调学习特定任务的向量会带来进一步的改进。
  - 最后，我们描述了对结构的简单修改，允许通过多通道使用预训练的和特定任务的向量。
  - 我们的工作在哲学上与Razavian等人（2014）相似，后者表明，对于图像分类，从预训练的深度学习模型中获得的特征提取器在各种任务中表现良好--包括与训练特征提取器的原始任务有很大不同的任务。


## 相关工作

**主要介绍背景知识。**

## 方法

- **简要地重复问题**
- **解决思路**
- **必要的形式化定义**
- **具体模型**



## 实验

- **数据集和实验设置**
- **主实验，提供详尽的实验分析**


## 讨论与总结



