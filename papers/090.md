# 090

**英文名称：** InPars: Data Augmentation for Information Retrieval using Large Language Models

**中文名称：** InPars：使用大型语言模型进行信息检索的数据增强

**论文地址：** https://arxiv.org/abs/2202.05144

**期刊/时间：** 2022

**代码地址：** https://github.com/zetaalphavector/inpars

## 前置知识

Pyserini是一个易于使用的Python工具包，通过在多阶段排名架构中提供有效的第一阶段检索，支持可复制的IR研究。工具包是作为标准Python软件包自包含的，并带有针对许多常用IR测试集合的查询，相关性判断，预建索引和评估脚本。旨在开箱即用地支持旨在提高现代神经方法排名的研究生命周期的整个过程。特别是，Pyserini支持稀疏检索（例如，使用词袋表示法进行BM25评分），密集检索（例如，对变压器编码的表示法进行最近邻居搜索），以及将两种方法集成在一起的混合检索。

## 摘要

- **问题是什么？**
- **本文要做什么？**
- **大概怎么做的**
- **实验效果**

由于大型预训练的转换模型，信息检索界最近迎来了一场革命。这场革命的另一个关键因素是MS MARCO数据集，它的规模和多样性使零散的转换学习能够应用于各种任务。然而，并非所有的IR任务和领域都能从一个单一的数据集中同样受益。对各种NLP任务的广泛研究表明，使用特定领域的训练数据，而不是通用的数据，可以提高神经模型的性能（Yu等人，2021；Sharami等人，2022）。在这项工作中，本文利用大型预训练语言模型的小样本能力作为IR任务的合成数据生成器。本文表明，仅在本文的无监督数据集上进行微调的模型优于强大的基线，如BM25以及最近提出的自我监督的密集检索方法。此外，在有监督数据和本文的合成数据上进行微调的检索器，比只在有监督数据上进行微调的模型实现了更好的零样本转移。

## 介绍

按照起承转合的思想阅读。
- **起。做的哪方面工作？**
- **承。相关工作**
- **转。相关工作的不足和转机**
- **合。本文工作**

语言模型（LM），如GPT3（Brown等人，2020）、FLAN（Wei等人，2022）、Gopher（Rae等人，2021）和T0++（Sanh等人，2021）已经在许多NLP任务上表现出令人印象深刻的性能。

此外，当一项任务没有足够的监督信息时，它们已被证明是有效的，有时会产生令人信服的结果（Winata等人，2021；Schick和Sch¨ utze，2021b）尽管大型LM的能力很吸引人，但在信息检索（IR）中很少使用数十亿的参数模型。对于一些明显的例外（Nogueira等人，2020；Pradeep等人，2021；Neelakantan等人，2022）。其中一个原因是信息检索任务的计算密集型性质。

例如，在一个典型的重新排序任务中，本文计算一个查询的1000个候选文件的相关性，这需要在重新排序模型上进行1000次推理。当使用大型模型时，这可能是非常昂贵的。例如，OpenAI提供了一个搜索API，允许人们使用他们具有数十亿参数的模型来计算查询-文档相关性。截至2022年2月，他们对最大的模型每1000个token收取0.06美元。如果每个候选文件包含250个token，那么使用这个API进行重新排序任务，每次查询的费用大约为15美元。

密集检索器（Karpukhin等人，2020；Khattab和Zaharia，2020）通过在检索前预先计算集合中每个文档的向量表示，避免了这个昂贵的重新排序步骤。当查询进来时，只计算其矢量表示，并且可以使用快速矢量搜索框架来检索与查询的矢量表示最近的文档矢量（Johnson等人，2019）。尽管在推理时计算成本较低，但密集检索器需要一个推理通道来计算集合中每个文档的向量表示，这也使得十亿参数的神经模型被用作密集检索器不切实际。

为IR开发神经模型的另一个挑战是缺乏特定领域的训练数据。手动构建高质量的数据集是很困难的，因为它需要来自真实用户的查询。虽然有一些通用的标记数据可用（Nguyen等人，2016；Kwiatkowski等人，2019），但它们在泛化到领域外的数据集方面并不总是有效的（Thakur等人，2021）。对于这个目标，零样本和小样本学习模型特别有希望。然而，在IR任务中使用大型LM的成本效益方式仍然是一个开放的问题

在这项工作中，本文提出了一种简单而有效的方法，即在检索中有效地使用大型LM，并在几个IR数据集中获得改进。本文没有在检索过程中直接使用大型LM，而是利用它们以小样本的方式生成标记的数据。然后，本文在这些合成数据上对检索模型进行微调，并利用它们对第一阶段检索系统的搜索结果进行排序。

- 本文提出了一种使大型LM适应IR任务的方法，避免由于其计算要求而无法使用。

- 在无监督的情况下，本文的方法在很大程度上超过了最近提出的方法。当与有监督的微调相结合时，本文的方法在本工作中评估的三个转移学习数据集中的两个取得了最先进的结果

## 相关工作

**主要介绍背景知识。**

数据增强方法旨在增加数据量，以协助数据驱动的模型的学习过程。为了提高神经模型在低资源环境下的性能，小规模的LM已经被用来在各种NLP任务中生成合成数据（Fadaee等人，2017；Kobayashi，2018）。

最近的工作表明，大型预训练的LM能够生成质量合理的数据（Anaby-Tavor等人，2020；Papanikolaou和Pierleoni，2020；Yang等人，2020；Mohapatra等人，2021；Kumar等人，2020；Schick和Sch¨ utze，2021a；Meng等人，2022），有时会比人类生成的数据集使用迁移学习的效果更好（Liu等人，2022）。

在信息检索中，如果只对没有注释的文档进行预训练，密集检索器可以在一些数据集中取得与BM25相当的结果（Ram等人，2021；Izacard等人，2021；Neelakantan等人，2022）。这些方法依赖于提取可能彼此相关的文本片段对，然后将其作为阳性对来训练检索模型。

Ma等人（2021）和Wang等人（2022）专注于提高密集型检索器的转移学习效率。

(2021)和Wang等人(2021)使用监督的序列到序列模型来增加训练数据。他们从不同文集的文本中生成问题，并将这些合成的问题-文本对作为积极的训练实例。本文的工作与现有的方法不同，因为本文完全依赖简单的提示，以最小的监督从大型语言模型中生成问题，即只使用少数监督的例子。本文的灵感主要来自于Han等人（2021），他们使用这样的模型以零样本的方式生成合成翻译对，即不使用任何平行语料。


## 方法

- **简要地重复问题**
- **解决思路**
- **必要的形式化定义**
- **具体模型**

给定一个文档 $d$ 和一个前缀 $t$ ，其中$t$包含了 $N$ 个问题对及相关文档,例如 $t=$ $\left\{\left(q_1^*, d_1^*\right), \ldots,\left(q_N^*, d_N^*\right)\right\}$, 本文使用语言模型 $G(t, d)$ 生成一个与文档 $d$ 最相关的问题 $q$ ，问题对 $(q, d)$ 组成了一个正向的训练示例，用于后面微调本文的检索模型。

我们使用从文档集 $D$ 中随机抽取的文档来生成数以千计的这些正向的训练例子。无论输入的文档是什么，前缀 $t$ 总是相同的，也就是说，我们只需使用 $N$ 个手动注释的例子就有可能生成数百万个合成训练例子。这使得我们的方法在 $N$ 较小的情况下成为一种小样本的学习方法（在我们的实验中，我们使用三个例子）。

作为创建训练数据集的最后一步，我们根据以下（对数）概率选择前K对。

$$
p_q=\frac{1}{|q|} \sum_{i=1}^{|q|} \log p\left(q_i \mid t, d, q_{<i}\right)
$$

其中，当自回归生成$q$的第$i$个token时，$p\left(q_i \mid t, d, q_{<i}\right)$ 是被$G$ 分配的概率。

基于小样本的特点，本文方法可以用来让检索器适应任何文集或IR任务，我们后来在各种文集上进行了经验性确认。这对于IR任务尤其重要，因为收集数据来训练检索模型是一个昂贵的过程（Yilmaz等人，2020年），大多数高质量的文集只有不到几百个查询（Voorhees和Harman，1999；Voorhees，2004）。

我们不进行任何预训练以使模型适应目标语料库，如Gao和Callan（2021）提出的那样。我们的方法不需要对损失函数进行任何修改，如Izacard等人（2021）；Neelakantan等人（2022）。这使得InPars也适用于非神经检索算法。

## 实验

- **数据集和实验设置**
- **主实验，提供详尽的实验分析**

### 生成训练数据
在这一节中，我们将描述这项工作中所使用的数据集，以及以小样本的方式从数据集中生成问题的程序，最后，我们如何在这些合成数据上训练检索器。我们的训练集包括一个查询、一个正面和一个负面文档的三元组。我们首先描述了查询和正面文档对是如何产生的。我们从集合中随机抽取100,000个文档，使用GPT-3的Curie作为我们的语言模型G，为每个文档生成一个问题。如果有标题的话，我们在文件文本前加上它的标题。少于300个字符的文件被丢弃，并对新的文件进行采样。我们使用一个0的温度，默认为贪婪解码。

使用两种提示模板来生成问题。
- Vanilla。从数据集中随机选择3对文档和相关的问题。
- GBQ（Guided by Bad Questions）。利用语言模型产生更加理解内容的问题

![20221021143900-2022-10-21-14-39-00](https://cdn.jsdelivr.net/gh/ironartisan/picRepo/20221021143900-2022-10-21-14-39-00.png)


我们的检索器是二元分类器，所以我们还需要选择与q不相关的文档来形成负的微调实例$（q，d^-）$。我们使用一个简单的方法，该方法已被证明对微调检索器是有效的（Pradeep等人，2021）。我们使用BM25，以q作为查询，从集合 $D$ 中检索出1000个文件，我们随机选择其中的一个作为$d^-$，这对$（q，d^-）$形成一个负面的例子。



### 检索方法

我们使用一个多阶段的检索架构，包括用词包BM25（ROBERTSON等人，1995）进行初始检索，然后是一个神经强化器。

使用pyserini（Lin等人，2021）对该文集进行索引，并使用BM25检索每个查询的1000个候选文件。

然后，我们使用monoT5对候选文档进行排名，monoT5是Nogueira等人（2020）提出的T5模型（Raffel等人，2020）对文本排名的一种改进。我们对monoT5基础（220M参数）和3B进行微调，学习率恒定为$10^{-3}$，每批大小为128的正反面例子数量相等。

## 讨论与总结

在这项工作中，本文提出了InPars，一种用大型LMs以小样本的方式为IR任务生成合成训练数据的方法。这使人们能够以更有效的方式利用大型模型学到的信息。

本文的实验表明，使用大型LM来生成合成训练数据是神经检索器发展的一个很有前景的方向。然而，在这项工作中还有许多方向没有探索到，本文将其作为未来的工作。
- 在本文的合成数据上对密集检索器进行微调；
- 使用 "坏问题 "作为负面的训练例子；
- 将本文的合成数据集扩展到数百万个例子；
- 用更复杂的方法选择（问题、相关文档）对。