# A.Note1:词向量、SVD分解与Word2Vec

CS224n是顶级院校斯坦福出品的深度学习与自然语言处理方向专业课程，核心内容覆盖RNN、LSTM、CNN、transformer、bert、问答、摘要、文本生成、语言模型、阅读理解等前沿内容。

本篇笔记对应斯坦福CS224n自然语言处理专项课程的第1个知识板块：NLP与词向量。首先介绍了自然语言处理(NLP)的概念及其面临的问题，进而介绍词向量和其构建方法（包括基于共现矩阵降维和Word2Vec）。

本节内容：
- 自然语言处理/Natural Language Processing(NLP)
- 词向量/Word Vectors
- SVD矩阵分解
- Skip-gram
- 负例采样
- transformer
- CBOW
- 层次化softmax
- Word2Vec
## 1.自然语言处理介绍
### 1.1 自然语言处理的特别之处

人类的语言有什么特别之处？人类语言是一个专门用来表达意义的系统，语言文字是上层抽象表征，NLP与计算机视觉或任何其他机器学习任务都有很大的不同。

大多数单词只是一个语言学以外的符号：单词是一个映射到所指(signified 想法或事物)的能指(signifier)。例如，“rocket”一词指的是火箭的概念，因此可以引申为火箭的实例。当我们使用单词和字母来表达符号时，也会有一些例外，例如“whoompaa”的使用。

最重要的是，这些语言的符号可以被编码成几种形式：声音、手势、文字等等，然后通过连续的信号传输给大脑；大脑本身似乎也能以一种连续的方式对这些信号进行解码。人们在语言哲学和语言学方面做了大量的工作来概念化人类语言，并将词语与其参照、意义等区分开来。

Natural language is a discrete[离散的] / symbolic[符号的] / categorical[分类的] system.

### 1.2 自然语言处理任务

自然语言处理有不同层次的任务，从语言处理到语义解释再到语篇处理。自然语言处理的目标是通过设计算法使得计算机能够“理解”语言，从而能够执行某些特定的任务。不同的任务的难度是不一样的：

- 简单任务
  - 拼写检查 Spell Checking
  - 关键词检索 Keyword Search
  - 同义词查找 Finding Synonyms
- 中级任务
  - 解析来自网站、文档等的信息
- 复杂任务
  - 机器翻译 Machine Translation
  - 语义分析 Semantic Analysis
  - 指代消解 Coreference
  - 问答系统 Question Answering

### 1.3 如何表征词汇

在所有的NLP任务中，第一个也是可以说是最重要的共同点是我们如何将单词表示为任何模型的输入。在这里我们不会讨论早期的自然语言处理工作是将单词视为原子符号 atomic symbols。

为了让大多数的自然语言处理任务能有更好的表现，我们首先需要了解单词之间的相似和不同。有了词向量，我们可以很容易地将其编码到向量本身中。

## 2.词向量

使用词向量编码单词， $$N$$ 维空间足够我们编码语言的所有语义，每一维度都会编码一些我们使用语言传递的信息。

**简单的one-hot向量无法给出单词间的相似性**，我们需要将维度 $$|V| $$ 减少至一个低纬度的子空间，来获得稠密的词向量，获得词之间的关系。

## 3.基于SVD降维的词向量

基于词共现矩阵与SVD分解是构建词嵌入(即词向量)的一种方法。

- 我们首先遍历一个很大的数据集和统计词的共现计数矩阵 $$X$$
- 然后对矩阵 $$X$$ 进行SVD分解得到 $$USV^T$$
- 再然后我们使用 $U$ 的行来作为字典中所有词的词向量
- 接下来我们讨论一下矩阵 公式 的几种选择。