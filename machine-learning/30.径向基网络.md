
# 径向基神经网络(RBF)


## 径向基函数

　　1985年，Powell提出了多变量插值的径向基函数（RBF）方法。径向基函数是一个取值仅仅依赖于离原点距离的实值函数，也就是Φ（x）=Φ(‖x‖),或者还可以是到任意一点c的距离，c点称为中心点，也就是Φ（x，c）=Φ(‖x-c‖)。任意一个满足Φ（x）=Φ(‖x‖)特性的函数Φ都叫做径向基函数，标准的一般使用欧氏距离（也叫做欧式径向基函数），尽管其他距离函数也是可以的。最常用的径向基函数是高斯核函数 ,形式为 $ k(||x-xc||)=exp{(- ||x-x_c||^2 /(2*σ)^2)) }$ 其中$x_c$为核函数中心,$σ$为函数的宽度参数 , 控制了函数的径向作用范围。

## RBF神经网络

　RBF神将网络是一种三层神经网络，其包括输入层、隐层、输出层。从输入空间到隐层空间的变换是非线性的，而从隐层空间到输出层空间变换是线性的。流图如下：

![20220527144156-2022-05-27-14-41-56](https://cdn.jsdelivr.net/gh/ironartisan/picRepo/20220527144156-2022-05-27-14-41-56.png)

　RBF网络的基本思想是：用RBF作为隐单元的“基”构成隐含层空间，这样就可以将输入矢量直接映射到隐空间，而不需要通过权连接。当RBF的中心点确定以后，这种映射关系也就确定了。而隐含层空间到输出空间的映射是线性的，即网络的输出是隐单元输出的线性加权和，此处的权即为网络可调参数。其中，隐含层的作用是把向量从低维度的p映射到高维度的h，这样低维度线性不可分的情况到高维度就可以变得线性可分了，主要就是核函数的思想。这样，网络由输入到输出的映射是非线性的，而网络输出对可调参数而言却又是线性的。网络的权就可由线性方程组直接解出，从而大大加快学习速度并避免局部极小问题。

径向基神经网络的激活函数可表示为：

![20220527144337-2022-05-27-14-43-37](https://cdn.jsdelivr.net/gh/ironartisan/picRepo/20220527144337-2022-05-27-14-43-37.png)

其中$x_p$径向基神经网络的结构可得到网络的输出为：

![20220527144357-2022-05-27-14-43-58](https://cdn.jsdelivr.net/gh/ironartisan/picRepo/20220527144357-2022-05-27-14-43-58.png)

当然，采用最小二乘的损失函数表示：

![20220527144413-2022-05-27-14-44-13](https://cdn.jsdelivr.net/gh/ironartisan/picRepo/20220527144413-2022-05-27-14-44-13.png)


## RBF神经网络与BP神经网络之间的区别

- 局部逼近与全局逼近：　

    　　BP神经网络的隐节点采用输入模式与权向量的内积作为激活函数的自变量，而激活函数采用Sigmoid函数。各调参数对BP网络的输出具有同等地位的影响，因此BP神经网络是对非线性映射的全局逼近。

    　　RBF神经网络的隐节点采用输入模式与中心向量的距离（如欧式距离）作为函数的自变量，并使用径向基函数（如Gaussian函数）作为激活函数。神经元的输入离径向基函数中心越远，神经元的激活程度就越低（高斯函数）。RBF网络的输出与部分调参数有关，譬如，一个$w_ij$值只影响一个$y_i$的输出，RBF神经网络因此具有“局部映射”特性。

    ![20220527144628-2022-05-27-14-46-28](https://cdn.jsdelivr.net/gh/ironartisan/picRepo/20220527144628-2022-05-27-14-46-28.png)

    　所谓局部逼近是指目标函数的逼近仅仅根据查询点附近的数据。而事实上，对于径向基网络，通常使用的是高斯径向基函数，函数图像是两边衰减且径向对称的，当选取的中心与查询点（即输入数据）很接近的时候才对输入有真正的映射作用，若中心与查询点很远的时候，欧式距离太大的情况下，输出的结果趋于0，所以真正起作用的点还是与查询点很近的点，所以是局部逼近；而BP网络对目标函数的逼近跟所有数据都相关，而不仅仅来自查询点附近的数据。

- 中间层数的区别
　　
    BP神经网络可以有多个隐含层，但是RBF只有一个隐含层。

- 训练速度的区别
　　使用RBF的训练速度快，一方面是因为隐含层较少，另一方面，局部逼近可以简化计算量。对于一个输入x，只有部分神经元会有响应，其他的都近似为0，对应的w就不用调参了。


- RBF网络是连续函数的最佳逼近，而BP网络不是。


## 参考链接

- <https://www.cnblogs.com/pinking/p/9349695.html>